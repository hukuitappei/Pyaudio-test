"""
Streamlit Cloudå¯¾å¿œéŸ³å£°éŒ²éŸ³ãƒ»æ–‡å­—èµ·ã“ã—ã‚¢ãƒ—ãƒªï¼ˆæ‹¡å¼µç‰ˆï¼‰
streamlit-audiorec + OpenAI Whisper API + è±Šå¯Œãªè¨­å®šæ©Ÿèƒ½
"""

import streamlit as st
import numpy as np
import wave
import io
import base64
import os
import tempfile
from datetime import datetime
from dotenv import load_dotenv
import json
import openai
from st_audiorec import st_audiorec

# æ‹¡å¼µæ©Ÿèƒ½ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from utils_audiorec import (
    EnhancedSettingsManager, 
    UserDictionaryManager, 
    CommandManager, 
    DeviceManager,
    save_audio_file,
    save_transcription_file
)
from settings_ui_audiorec import (
    render_enhanced_settings_tab,
    render_user_dictionary_tab,
    render_commands_tab,
    render_file_management_tab
)

# ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="éŸ³å£°éŒ²éŸ³ãƒ»æ–‡å­—èµ·ã“ã—ã‚¢ãƒ—ãƒª (streamlit-audiorecç‰ˆ)",
    page_icon="ğŸ¤",
    layout="wide"
)

class AudioTranscriptionManager:
    """éŸ³å£°æ–‡å­—èµ·ã“ã—ç®¡ç†ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.openai_client = None
        self.setup_openai()
    
    def setup_openai(self):
        """OpenAI APIã®è¨­å®š"""
        api_key = os.getenv("OPENAI_API_KEY")
        if api_key:
            self.openai_client = openai.OpenAI(api_key=api_key)
        else:
            st.warning("âš ï¸ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚æ–‡å­—èµ·ã“ã—æ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")
    
    def transcribe_audio(self, audio_data, filename="recording.wav"):
        """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ–‡å­—èµ·ã“ã—"""
        if not self.openai_client:
            return None, "OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“"
        
        try:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
                tmp_file.write(audio_data)
                tmp_file_path = tmp_file.name
            
            # OpenAI Whisper APIã§æ–‡å­—èµ·ã“ã—
            with open(tmp_file_path, "rb") as audio_file:
                response = self.openai_client.audio.transcriptions.create(
                    model="whisper-1",
                    file=audio_file,
                    language="ja"
                )
            
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            os.unlink(tmp_file_path)
            
            return response.text, None
            
        except Exception as e:
            return None, f"æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {str(e)}"

# è¨­å®šç®¡ç†ã‚¯ãƒ©ã‚¹ã¯ utils_audiorec.py ã«ç§»å‹•æ¸ˆã¿

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    st.title("ğŸ¤ éŸ³å£°éŒ²éŸ³ãƒ»æ–‡å­—èµ·ã“ã—ã‚¢ãƒ—ãƒªï¼ˆæ‹¡å¼µç‰ˆï¼‰")
    st.write("Streamlit Cloudå¯¾å¿œã®ãƒ–ãƒ©ã‚¦ã‚¶ãƒ™ãƒ¼ã‚¹éŸ³å£°éŒ²éŸ³ãƒ»æ–‡å­—èµ·ã“ã—ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³")
    
    # è¨­å®šãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆæœŸåŒ–
    settings_manager = EnhancedSettingsManager()
    transcription_manager = AudioTranscriptionManager()
    
    # ã‚¿ãƒ–ã®ä½œæˆ
    tab1, tab2, tab3, tab4, tab5 = st.tabs([
        "ğŸ¤ éŒ²éŸ³ãƒ»æ–‡å­—èµ·ã“ã—", 
        "âš™ï¸ æ‹¡å¼µè¨­å®š", 
        "ğŸ“š ãƒ¦ãƒ¼ã‚¶ãƒ¼è¾æ›¸", 
        "âš¡ ã‚³ãƒãƒ³ãƒ‰ç®¡ç†", 
        "ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†"
    ])
    
    with tab1:
        st.subheader("ğŸ¤ éŸ³å£°éŒ²éŸ³ãƒ»æ–‡å­—èµ·ã“ã—")
        
        # è¨­å®šã‚’èª­ã¿è¾¼ã¿
        settings = settings_manager.load_settings()
        
        st.write("**æ©Ÿèƒ½**: streamlit-audiorec + OpenAI Whisper API + æ‹¡å¼µè¨­å®šæ©Ÿèƒ½")
        st.write("**æ³¨æ„**: ã“ã®ã‚¢ãƒ—ãƒªã¯ãƒ–ãƒ©ã‚¦ã‚¶ã®ãƒã‚¤ã‚¯æ¨©é™ã‚’ä½¿ç”¨ã—ã¾ã™")
        
        # æ–‡å­—èµ·ã“ã—æ©Ÿèƒ½ã®èª¬æ˜
        with st.expander("ğŸ“ æ–‡å­—èµ·ã“ã—æ©Ÿèƒ½ã«ã¤ã„ã¦"):
            st.write("""
            **OpenAI Whisper APIã‚’ä½¿ç”¨ã—ãŸé«˜ç²¾åº¦æ–‡å­—èµ·ã“ã—**
            
            âœ… **ç‰¹å¾´**:
            - é«˜ç²¾åº¦ãªéŸ³å£°èªè­˜
            - æ—¥æœ¬èªå¯¾å¿œ
            - è‡ªå‹•è¨€èªæ¤œå‡º
            - å¥èª­ç‚¹ã®è‡ªå‹•æŒ¿å…¥
            
            âœ… **ä½¿ç”¨æ–¹æ³•**:
            1. éŒ²éŸ³ã‚’é–‹å§‹
            2. éŒ²éŸ³å®Œäº†å¾Œã€è‡ªå‹•ã¾ãŸã¯æ‰‹å‹•ã§æ–‡å­—èµ·ã“ã—
            3. çµæœã‚’ã‚³ãƒ”ãƒ¼ã¾ãŸã¯ä¿å­˜
            
            âš ï¸ **æ³¨æ„**: OpenAI APIã‚­ãƒ¼ãŒå¿…è¦ã§ã™
            """)
        
        # éŒ²éŸ³ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
        st.write("### ğŸ¤ éŒ²éŸ³")
        
        # éŒ²éŸ³ãƒœã‚¿ãƒ³
        audio = st_audiorec()
        
        if audio is not None:
            # éŒ²éŸ³ãƒ‡ãƒ¼ã‚¿ã®å‡¦ç†ï¼ˆst_audiorecã¯ç›´æ¥bytesã‚’è¿”ã™ï¼‰
            audio_data = audio
            
            # éŒ²éŸ³æƒ…å ±ã®è¡¨ç¤ºï¼ˆç°¡æ˜“ç‰ˆï¼‰
            st.write("**éŒ²éŸ³å®Œäº†**")
            st.write(f"**ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º**: {len(audio_data)} bytes")
            
            # éŸ³å£°ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼
            st.audio(audio_data, format="audio/wav")
            
            # è‡ªå‹•ä¿å­˜
            if settings["ui"]["auto_save_recordings"]:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"recording_{timestamp}.wav"
                if save_audio_file(audio_data, filename):
                    st.success(f"âœ… éŒ²éŸ³ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filename}")
            
            # æ–‡å­—èµ·ã“ã—ã‚»ã‚¯ã‚·ãƒ§ãƒ³
            st.write("### ğŸ“ æ–‡å­—èµ·ã“ã—")
            
            col1, col2 = st.columns(2)
            
            with col1:
                if st.button("ğŸ™ï¸ æ–‡å­—èµ·ã“ã—é–‹å§‹"):
                    with st.spinner("æ–‡å­—èµ·ã“ã—ä¸­..."):
                        transcription, error = transcription_manager.transcribe_audio(audio_data)
                        
                        if transcription:
                            st.session_state['transcription'] = transcription
                            st.success("âœ… æ–‡å­—èµ·ã“ã—å®Œäº†")
                        else:
                            st.error(f"âŒ {error}")
            
            with col2:
                if st.button("ğŸ’¾ æ–‡å­—èµ·ã“ã—çµæœã‚’ä¿å­˜"):
                    if 'transcription' in st.session_state:
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        filename = f"transcription_{timestamp}.txt"
                        
                        if save_transcription_file(st.session_state['transcription'], filename):
                            st.success(f"âœ… æ–‡å­—èµ·ã“ã—çµæœã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filename}")
                        else:
                            st.error("âŒ ä¿å­˜ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
                    else:
                        st.warning("æ–‡å­—èµ·ã“ã—çµæœãŒã‚ã‚Šã¾ã›ã‚“")
            
            # æ–‡å­—èµ·ã“ã—çµæœã®è¡¨ç¤º
            if 'transcription' in st.session_state:
                st.write("**æ–‡å­—èµ·ã“ã—çµæœ:**")
                st.text_area("", st.session_state['transcription'], height=200)
                
                # ã‚³ãƒ”ãƒ¼ãƒœã‚¿ãƒ³
                if st.button("ğŸ“‹ ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ã‚³ãƒ”ãƒ¼"):
                    st.write("æ–‡å­—èµ·ã“ã—çµæœã‚’ã‚¯ãƒªãƒƒãƒ—ãƒœãƒ¼ãƒ‰ã«ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸ")
                    st.code(st.session_state['transcription'])
    
    with tab2:
        settings = render_enhanced_settings_tab(settings_manager)
        if st.button("ğŸ’¾ è¨­å®šã‚’ä¿å­˜"):
            if settings_manager.save_settings(settings):
                st.success("âœ… è¨­å®šã‚’ä¿å­˜ã—ã¾ã—ãŸ")
            else:
                st.error("âŒ è¨­å®šã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ")
    
    with tab3:
        render_user_dictionary_tab()
    
    with tab4:
        render_commands_tab()
    
    with tab5:
        render_file_management_tab()
    
    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown("**Streamlit Cloudå¯¾å¿œ** - streamlit-audiorec + OpenAI Whisper API + æ‹¡å¼µè¨­å®šæ©Ÿèƒ½ã‚’ä½¿ç”¨ã—ãŸãƒ–ãƒ©ã‚¦ã‚¶ãƒ™ãƒ¼ã‚¹éŒ²éŸ³ãƒ»æ–‡å­—èµ·ã“ã—")

if __name__ == "__main__":
    main() 