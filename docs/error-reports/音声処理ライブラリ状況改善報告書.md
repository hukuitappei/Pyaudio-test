# 音声処理ライブラリ状況改善報告書

## 現在のライブラリ状況

### ✅ 利用可能なライブラリ
- **OpenAI**: 文字起こし機能が利用可能
- **SciPy**: 音声処理の代替手段として利用可能

### ❌ 利用不可のライブラリ
- **PyAudio**: 直接録音機能が利用不可
- **st_audiorec**: Streamlit録音コンポーネントが利用不可
- **SoundFile**: 音声ファイル読み書きが利用不可
- **Librosa**: 音声分析が利用不可
- **PyDub**: 音声処理が利用不可

## 実装した改善

### 1. SciPy優先の音声処理システム

#### 音声ファイル保存の改善
```python
def save_audio_file(audio_data: np.ndarray, filename: str, sample_rate: int = 44100) -> bool:
    """音声ファイルを保存（SciPy優先版）"""
    
    # 1. scipyライブラリを優先使用（最も安定）
    if SCIPY_AVAILABLE:
        try:
            from scipy.io import wavfile
            wavfile.write(filename, sample_rate, audio_data)
            st.success(f"✅ 音声ファイルを保存しました: {filename}")
            return True
        except Exception as e:
            st.warning(f"scipyでの保存に失敗: {e}")
    
    # 2. soundfileライブラリを試行
    # 3. pydubライブラリを試行
    # 4. フォールバック: 生のWAVファイルとして保存
```

#### 音声ファイル読み込みの改善
```python
def load_audio_file(filename: str) -> Optional[Tuple[np.ndarray, int]]:
    """音声ファイルを読み込み（SciPy優先版）"""
    
    # 1. scipyライブラリを優先使用（最も安定）
    if SCIPY_AVAILABLE:
        try:
            from scipy.io import wavfile
            sample_rate, audio_data = wavfile.read(filename)
            st.success(f"✅ 音声ファイルを読み込みました: {filename}")
            return audio_data, sample_rate
        except Exception as e:
            st.warning(f"scipyでの読み込みに失敗: {e}")
    
    # 2. soundfileライブラリを試行
    # 3. pydubライブラリを試行
    # 4. フォールバック: 生のWAVファイルとして読み込み
```

### 2. SciPyを使用した音声分析機能

#### 音声分析機能
```python
def analyze_audio_with_scipy(audio_data: np.ndarray, sample_rate: int) -> Dict[str, Any]:
    """SciPyを使用した音声分析"""
    
    # 基本統計情報
    analysis["mean"] = float(stats.mean)
    analysis["variance"] = float(stats.variance)
    analysis["skewness"] = float(stats.skewness)
    analysis["kurtosis"] = float(stats.kurtosis)
    
    # 音量レベル（RMS）
    rms = np.sqrt(np.mean(audio_data**2))
    analysis["rms_level"] = float(rms)
    
    # 最大振幅
    max_amplitude = np.max(np.abs(audio_data))
    analysis["max_amplitude"] = float(max_amplitude)
    
    # 動的範囲
    dynamic_range = 20 * np.log10(max_amplitude / (rms + 1e-10))
    analysis["dynamic_range_db"] = float(dynamic_range)
    
    # スペクトラム分析
    freqs, psd = signal.welch(audio_data, sample_rate, nperseg=1024)
    analysis["dominant_frequency"] = float(freqs[np.argmax(psd)])
    analysis["spectral_centroid"] = float(np.sum(freqs * psd) / np.sum(psd))
    
    # ゼロクロス率（音声の特徴量）
    zero_crossings = np.sum(np.diff(np.sign(audio_data)) != 0)
    analysis["zero_crossing_rate"] = float(zero_crossings / len(audio_data))
    
    # 音声の長さ
    duration = len(audio_data) / sample_rate
    analysis["duration_seconds"] = float(duration)
```

#### 音声エンハンスメント機能
```python
def enhance_audio_with_scipy(audio_data: np.ndarray, sample_rate: int, 
                           gain: float = 1.0, noise_reduction: bool = False) -> np.ndarray:
    """SciPyを使用した音声エンハンスメント"""
    
    # ゲイン調整
    if gain != 1.0:
        enhanced_audio = enhanced_audio * gain
    
    # ノイズリダクション（簡単なローパスフィルタ）
    if noise_reduction:
        # バターワースローパスフィルタ
        nyquist = sample_rate / 2
        cutoff = 8000  # 8kHz以下を通過
        order = 5
        b, a = signal.butter(order, cutoff / nyquist, btype='low')
        enhanced_audio = signal.filtfilt(b, a, enhanced_audio)
```

#### 無音区間検出機能
```python
def detect_silence(audio_data: np.ndarray, sample_rate: int, 
                  threshold: float = 0.01, min_duration: float = 0.5) -> List[Dict[str, float]]:
    """無音区間の検出"""
    
    # 音量レベルを計算
    window_size = int(sample_rate * 0.1)  # 100msウィンドウ
    rms = np.array([np.sqrt(np.mean(audio_data[i:i+window_size]**2)) 
                   for i in range(0, len(audio_data) - window_size, window_size)])
    
    # 無音区間を検出
    silence_mask = rms < threshold
    silence_regions = []
    
    # 連続する無音区間をグループ化
    silence_starts = np.where(np.diff(silence_mask.astype(int)) == 1)[0]
    silence_ends = np.where(np.diff(silence_mask.astype(int)) == -1)[0]
```

### 3. 録音機能の改善

#### 録音機能の代替案提供
```python
def record_audio(duration: int = 5, sample_rate: int = 44100, channels: int = 1) -> Optional[np.ndarray]:
    """音声録音機能（Streamlit Cloud対応）"""
    
    if not PYAUDIO_AVAILABLE:
        st.warning("⚠️ 直接録音機能は利用できません")
        st.info("💡 以下の方法で音声を録音してください:")
        st.info("1. ブラウザの録音機能を使用")
        st.info("2. 外部アプリで録音してファイルをアップロード")
        st.info("3. 音声ファイルを直接アップロード")
        
        # 代替案としてダミーデータを生成（テスト用）
        if st.button("🎵 テスト用音声データを生成"):
            st.info("テスト用の正弦波音声データを生成します...")
            t = np.linspace(0, duration, int(sample_rate * duration), False)
            # 440Hzの正弦波
            test_audio = np.sin(2 * np.pi * 440 * t) * 0.3
            # 16-bit整数に変換
            test_audio = (test_audio * 32767).astype(np.int16)
            st.success("✅ テスト用音声データを生成しました")
            return test_audio
```

### 4. ライブラリ状況表示の改善

#### 優先順位付きライブラリ表示
```python
def show_audio_library_status():
    """音声処理ライブラリの利用状況を表示"""
    
    # 音声処理ライブラリ（優先順位順）
    st.sidebar.write(f"**SciPy**: {'✅ 利用可能' if SCIPY_AVAILABLE else '❌ 利用不可'}")
    st.sidebar.write(f"**SoundFile**: {'✅ 利用可能' if SOUNDFILE_AVAILABLE else '❌ 利用不可'}")
    st.sidebar.write(f"**Librosa**: {'✅ 利用可能' if LIBROSA_AVAILABLE else '❌ 利用不可'}")
    st.sidebar.write(f"**PyDub**: {'✅ 利用可能' if PYDUB_AVAILABLE else '❌ 利用不可'}")
    
    # 利用可能なライブラリの概要
    available_libs = get_available_audio_libraries()
    if available_libs:
        st.sidebar.success(f"✅ 利用可能: {', '.join(available_libs)}")
        
        # SciPyが利用可能な場合の追加情報
        if SCIPY_AVAILABLE:
            st.sidebar.info("💡 SciPyを使用した音声分析・エンハンスメント機能が利用可能です")
```

## 改善効果

### 1. 音声処理の安定性向上
- SciPyを優先使用することで、音声ファイルの読み書きが安定化
- エラーハンドリングの強化により、処理失敗時の適切な対処が可能

### 2. 音声分析機能の追加
- 基本統計情報（平均、分散、歪度、尖度）
- 音量レベル（RMS）と最大振幅
- 動的範囲（dB）
- スペクトラム分析（主要周波数、スペクトラム重心）
- ゼロクロス率（音声の特徴量）
- 音声の長さ

### 3. 音声エンハンスメント機能
- ゲイン調整
- ノイズリダクション（ローパスフィルタ）

### 4. 無音区間検出機能
- 音声内の無音区間を自動検出
- 無音区間の開始時間、終了時間、継続時間を取得

### 5. ユーザビリティの向上
- 利用可能なライブラリの明確な表示
- 録音機能が利用できない場合の代替案提示
- テスト用音声データの生成機能

## 修正ファイル
- `src/utils_audiorec.py`: 音声処理機能の改善
- `docs/error-reports/音声処理ライブラリ状況改善報告書.md`: 本報告書

## 修正日時
2025年1月現在

## 修正者
AI Assistant

## 次のステップ
1. アプリケーションの再起動
2. SciPyを使用した音声分析機能の動作確認
3. 音声エンハンスメント機能の動作確認
4. 無音区間検出機能の動作確認
5. テスト用音声データ生成機能の動作確認

## 期待される結果
- SciPyを使用した安定した音声処理
- 詳細な音声分析機能の提供
- 音声エンハンスメント機能の提供
- 無音区間検出機能の提供
- 録音機能が利用できない場合の適切な代替案提示
- ユーザーが音声処理機能を理解しやすくなる
